{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471fc927",
   "metadata": {},
   "source": [
    "This notebook contains the code to evaluate within subject cross session gradient peak locations. \n",
    "It also is set up to create ROIs for distance measurements to the rest of the cortex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a25300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/austin/.local/lib/python3.8/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension mayavi/x3d/x3dom...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n",
      "Notebook initialized with png backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import nibabel as nib \n",
    "\n",
    "import nilearn.plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import mayavi\n",
    "from mayavi import mlab\n",
    "import ptitprince as pt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import gdist\n",
    "import surfdist as sd \n",
    "import surfdist.analysis  \n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.offsetbox as offsetbox\n",
    "!jupyter nbextension enable mayavi --user --py\n",
    "mlab.init_notebook('png',1500,1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b07ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects=!ls -d *10*/\n",
    "for i in range(len(subjects)):\n",
    "    subjects[i]=subjects[i].split('/')[0]\n",
    "#### load watersheds\n",
    "LWS=nib.load('/Users/austin/Documents/ParisHorizontal/Mai2022Grads/watershedTemplates/LWS.28.max.label.gii').darrays[0].data\n",
    "RWS=nib.load('/Users/austin/Documents/ParisHorizontal/Mai2022Grads/watershedTemplates/RWS.28.max.label.gii').darrays[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b55efe",
   "metadata": {},
   "source": [
    "By defining the hcp_subj class, operations are relatively contained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432c3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import nibabel as nib \n",
    "\n",
    "import nilearn.plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import mayavi\n",
    "from mayavi import mlab\n",
    "import ptitprince as pt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import gdist\n",
    "import surfdist as sd \n",
    "import surfdist.analysis  \n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def recort(X,fill,dims):\n",
    "    out=np.zeros(dims)\n",
    "    out[fill]=X\n",
    "    return out\n",
    "\n",
    "def recort_bin(X,fill,dims):\n",
    "    out=np.zeros(dims)\n",
    "    mini=np.zeros(len(fill))\n",
    "    mini[X]=1\n",
    "    out[fill]=mini\n",
    "    return out\n",
    "    \n",
    "\n",
    "def binit(X):\n",
    "    pct=np.percentile(X,[10,20,30,40,50,60,70,80,90])\n",
    "    pct=np.digitize(X,pct)\n",
    "    return pct+1 \n",
    "\n",
    "def binit20(X):\n",
    "    pct=np.percentile(X,[20,40,60,80])\n",
    "    pct=np.digitize(X,pct)\n",
    "    return pct+1 \n",
    "\n",
    "\n",
    "def get_zoneVerts(WS):\n",
    "    zoneverts={}\n",
    "    for i in range(1,np.max(WS)):\n",
    "        zoneverts.update({f'zone{i}':np.where(WS==i)[0]})\n",
    "    return zoneverts\n",
    "\n",
    "def oh_mayavi(surf,stat,cmap,clrbar=True):\n",
    "    \"\"\"surface, statmap, colormap\"\"\"\n",
    "    ##### parse the gifti \n",
    "    anat=nib.load(surf)\n",
    "    coords=anat.darrays[0].data\n",
    "    x=coords[:,0]\n",
    "    y=coords[:,1]\n",
    "    z=coords[:,2]\n",
    "    triangles=anat.darrays[1].data\n",
    "    ##### if subcortical mask provided use it\n",
    "\n",
    "#         print('masking out subcortex')\n",
    "#     sub_cort=nilearn.surface.load_surf_data(args[0])\n",
    "#     stat[sub_cort]=float('NaN')\n",
    "\n",
    "    \n",
    "    \n",
    "    ### start mayavi \n",
    "    \n",
    "    maya=mlab.triangular_mesh(x,y,z,triangles,scalars=stat,colormap=cmap)\n",
    "    \n",
    "    mlab.view(azimuth=0, elevation=-90)\n",
    "    f = mlab.gcf()\n",
    "    cam = f.scene.camera\n",
    "    cam.zoom(1.)\n",
    "    if clrbar==True:\n",
    "        cb=mlab.colorbar(orientation='vertical', nb_labels=3,label_fmt='%.2f')\n",
    "        cb.label_text_property.color =(0,0,0)\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    mlab.draw()\n",
    "    \n",
    "\n",
    "    img1=mlab.screenshot(figure=maya,mode='rgba',antialiased=True)\n",
    "    mlab.view(azimuth=0, elevation=90)\n",
    "    mlab.figure(bgcolor=(0, 0, 0))\n",
    "    ### clear figure\n",
    "    mayavi.mlab.clf()\n",
    "    \n",
    "    f = mlab.gcf()\n",
    "    cam = f.scene.camera\n",
    "    cam.zoom(1.1)\n",
    "    mlab.draw()\n",
    "    img2=mlab.screenshot(figure=maya,mode='rgba',antialiased=True)\n",
    "    ### clear figure\n",
    "    mayavi.mlab.clf()\n",
    "    mlab.clf()\n",
    "    mlab.close()\n",
    "    return img1,img2\n",
    "\n",
    "\n",
    "def plot_srfs(a,b,c,d):\n",
    "    figure=plt.figure(figsize=(6, 8), dpi=180)\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(a)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(b)\n",
    "    plt.axis('off')\n",
    "    mlab.clf()\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(c)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.imshow(d)\n",
    "    plt.axis('off')\n",
    "    \n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.5, \n",
    "                        top=0.9, \n",
    "                        wspace=0, \n",
    "                        hspace=0)\n",
    "#     plt.savefig(f'{file}.png',bbox_inches='tight',facecolor='w')\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "def dice_it(A,B):\n",
    "    \n",
    "    num=2*(len(np.intersect1d(A,B)))\n",
    "    den=len(A)+len(B)\n",
    "    \n",
    "    if den ==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return num/den\n",
    "\n",
    "def jaccard_it(A,B):\n",
    "    num=len(np.intersect1d(A,B))\n",
    "    den=len(np.union1d(A,B))\n",
    "    \n",
    "    if den ==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num/den\n",
    "\n",
    "def gradientOrientation(grad,hemi,aparc):\n",
    "    \"\"\"Determine the orientation of the gradients, and also return whether valid for continued study or not\"\"\"\n",
    "    grad=grad #nib.load(grad).agg_data()\n",
    "    if hemi=='left':\n",
    "        labels=nib.load(aparc).agg_data()\n",
    "#       print('getting gradient orientation from left hemisphere')\n",
    "    else:\n",
    "        labels=nib.load(aparc).agg_data()\n",
    "#       print('getting gradient orientation from right hemisphere')\n",
    "    calc=np.where(labels==45)[0]\n",
    "    ctr=np.where(labels==46)[0]\n",
    "    if np.sum(grad[calc])<0 and np.sum(grad[ctr])<0:\n",
    "#       print('Canonical Orientation DMN at apex')\n",
    "        return grad,True\n",
    "    elif np.sum(grad[calc])<0 and np.sum(grad[ctr])>0:\n",
    "#       print(f'REMOVE {subj} FROM STUDY')\n",
    "        return grad,False\n",
    "    elif np.sum(grad[calc])>0 and np.sum(grad[ctr])<0:\n",
    "#       print(f'REMOVE {subj} FROM STUDY')\n",
    "        return grad,False\n",
    "    else:\n",
    "#       print('flipping gradient orientation for peak detection')\n",
    "        return grad *-1,True\n",
    "\n",
    "\n",
    "def prep_plotting(subj,kernel,sim='dice',pca=False):\n",
    "    \n",
    "    thr=[50,55,60,65,70,75,80,85,90,95]\n",
    "    \n",
    "    ctx_metric=[]\n",
    "    zone_metricsL=[]\n",
    "    zone_metricsR=[]\n",
    "    \n",
    "    if pca == False:\n",
    "        gr=hcp_subj(subj,kernel)\n",
    "        if gr.Lgradses1[1] == False or gr.Lgradses2[1] == False or gr.Rgradses1[1] ==False or gr.Rgradses2[1] ==False:\n",
    "#             print(f'subject {gr.subj} Diffusion Mapping is not valid at smoothing kernel {kernel} ')\n",
    "            return [gr.subj,kernel],[gr.subj,kernel],[gr.subj,kernel]\n",
    "        else:\n",
    "            if sim=='dice':\n",
    "                for t in thr:\n",
    "                    ctx_metric.append(gr.dice_Ses12(t))\n",
    "                    zone_metricsL.append(gr.ZoneDice_Ses12(t)[0])\n",
    "                    zone_metricsR.append(gr.ZoneDice_Ses12(t)[1])\n",
    "            else: \n",
    "                for t in thr:\n",
    "                    gr.Jaccard_Ses12(t)\n",
    "                    ctx_metric.append(gr.Jaccard_Ses12(t))\n",
    "                    zone_metricsL.append(gr.ZoneDice_Ses12(t)[0])\n",
    "                    zone_metricsR.append(gr.ZoneDice_Ses12(t)[1])\n",
    "                    \n",
    "        \n",
    "    else:\n",
    "        gr=hcp_subj(subj,kernel,pca=True)\n",
    "        if gr.Lgradses1[1] == False or gr.Lgradses2[1] == False or gr.Rgradses1[1] ==False or gr.Rgradses2[1] ==False:\n",
    "#             print(f'subject {gr.subj} PCA is not valid at smoothing kernel {kernel} ')\n",
    "            return [gr.subj,kernel],[gr.subj,kernel],[gr.subj,kernel]\n",
    "        else:\n",
    "            if sim=='dice':\n",
    "                for t in thr:\n",
    "                    ctx_metric.append(gr.dice_Ses12(t))\n",
    "                    zone_metricsL.append(gr.ZoneDice_Ses12(t)[0])\n",
    "                    zone_metricsR.append(gr.ZoneDice_Ses12(t)[1])\n",
    "            else: \n",
    "                for t in thr:\n",
    "                    gr.Jaccard_Ses12(t)\n",
    "                    ctx_metric.append(gr.Jaccard_Ses12(t))\n",
    "                    \n",
    "                    zone_metricsL.append(gr.ZoneDice_Ses12(t)[0])\n",
    "                    zone_metricsR.append(gr.ZoneDice_Ses12(t)[1])\n",
    "                    \n",
    "    return np.vstack(ctx_metric),np.vstack(zone_metricsL),np.vstack(zone_metricsR)\n",
    "\n",
    "\n",
    "def prep_plotsXkernel(kernel,pca=False,corr=True):\n",
    "    ### set up outputs\n",
    "    Lhemi=[]\n",
    "    Rhemi=[]\n",
    "    LlatPar=[]\n",
    "    LTmp=[]\n",
    "    LmedPar=[]\n",
    "    RlatPar=[]\n",
    "    RTmp=[]\n",
    "    RmedPar=[]\n",
    "    \n",
    "    nogo=[]\n",
    "    \n",
    "    ### loop through subjjects for specified kernel\n",
    "    for subj in subjects:\n",
    "        a,b,c=prep_plotting(subj,kernel,pca=pca)\n",
    "        if len(a)>2:\n",
    "            Lhemi.append(a[:,0])\n",
    "            Rhemi.append(a[:,1])\n",
    "        \n",
    "            LlatPar.append(b[:,0])\n",
    "            LTmp.append(b[:,1])\n",
    "            LmedPar.append(b[:,2])\n",
    "        \n",
    "            RlatPar.append(c[:,0])\n",
    "            RTmp.append(c[:,1])\n",
    "            RmedPar.append(c[:,2])\n",
    "        else:\n",
    "            nogo.append(a[0])\n",
    "    Lhemi=np.vstack(Lhemi)\n",
    "    Rhemi=np.vstack(Rhemi)\n",
    "    \n",
    "    LlatPar=np.vstack(LlatPar)\n",
    "    LTmp=np.vstack(LTmp)\n",
    "    LmedPar=np.vstack(LmedPar)\n",
    "    \n",
    "    RlatPar=np.vstack(LlatPar)\n",
    "    RTmp=np.vstack(LTmp)\n",
    "    RmedPar=np.vstack(LmedPar)\n",
    "    \n",
    "    if corr == True:\n",
    "        corr=(len(Lhemi)/len(subjects))\n",
    "        return   (Lhemi*corr),(Rhemi*corr),(LlatPar*corr),(LTmp*corr),(LmedPar*corr),(RlatPar*corr),(RTmp*corr),(RmedPar*corr),nogo\n",
    "    elif corr == False:\n",
    "        return  Lhemi,Rhemi,LlatPar,LTmp,LmedPar,RlatPar,RTmp,RmedPar,nogo\n",
    "    \n",
    "def plot_itHue(k,rgn,legend=False,corr=True):\n",
    "    \"\"\"where k = kernel of 2,4,6,8,10 and rgn indexes the output of prep\"\"\"\n",
    "    if corr==True:\n",
    "        a=prep_plotsXkernel(k)\n",
    "        b=prep_plotsXkernel(k,pca=True)\n",
    "    elif corr==False:\n",
    "        a=prep_plotsXkernel(k,corr=False)\n",
    "        b=prep_plotsXkernel(k,pca=True,corr=False)\n",
    "\n",
    "    a=pd.DataFrame.from_dict(dict(zip(thr,a[rgn].T)))\n",
    "    a['Method']='Diffusion Mapping'\n",
    "    b=pd.DataFrame.from_dict(dict(zip(thr,b[rgn].T)))\n",
    "    b['Method']='PCA'\n",
    "\n",
    "#     print(f'Dmaps has {len(a)} subjects')\n",
    "#     print(f'PCA has {len(b)} subjects')\n",
    "#     print(f'smoothing kernel is {k}')\n",
    "    df=pd.concat([a,b])\n",
    "    df=df.melt(id_vars=['Method'],value_vars=[50,55,60,65,70,75,80,85,90,95])\n",
    "#     f, ax = plt.figure()\n",
    "    ax=sn.boxplot(data=df,x='value',y='variable',hue='Method',orient='h')\n",
    "    ax=sn.stripplot(data=df,x='value',y='variable',hue='Method',orient='h',size=3,dodge=True,palette=pal)\n",
    "    \n",
    "    plt.xlim([0,1])\n",
    "    ax.set(ylabel = \"\")\n",
    "    plt.xlabel(f\"{k}mm Smoothing.\\n Dmap with {len(a)}/20 \\n PCA with {len(b)}/20 subjects\", fontsize=12)\n",
    "    ax.set(xlim=[0,1])\n",
    "    \n",
    "    if legend==False:\n",
    "        ax.get_legend().remove()\n",
    "    else: \n",
    "        ax.legend(bbox_to_anchor=(1.02, 0.55), loc='upper left', borderaxespad=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_srfs_dice(a,b,c,d,title,diceL,diceR):\n",
    "    figure=plt.figure(figsize=(2,4), dpi=180)\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(a)\n",
    "    plt.title(diceL,fontsize=6)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,2,2)\n",
    "    \n",
    "    plt.imshow(b)\n",
    "    plt.axis('off')\n",
    "    mlab.clf()\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(c)\n",
    "    plt.title(diceR,fontsize=6)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.imshow(d)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    figure.suptitle(title, fontsize=6)\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.5, \n",
    "                        top=0.9, \n",
    "                        wspace=-0.1, \n",
    "                        hspace=0)\n",
    "    mlab.close()\n",
    "    return figure\n",
    "#     plt.savefig(f'{file}.png',bbox_inches='tight',facecolor='w')\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb42e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hcp_subj:\n",
    "\n",
    "    def __init__(self,subj,kernel,pca=None):\n",
    "        \n",
    "        self.subj=subj\n",
    "        self.info=np.load(f'{subj}/{subj}.cifti.info.npy',allow_pickle=True).item()\n",
    "        \n",
    "        self.dims=self.info['lnverts']\n",
    "        self.Lfill=self.info['lIDX']\n",
    "        self.Rfill=self.info['rIDX']\n",
    "        self.pca=pca\n",
    "        \n",
    "        self.Lsrf=f'../data20/{subj}/Structural/{subj}.L.midthickness.32k_fs_LR.surf.gii'\n",
    "        self.Lcoords=nib.load(self.Lsrf).darrays[0].data\n",
    "        self.Linflated='/Users/austin/Documents/ParisHorizontal/32k_fs_LR/S1200.L.inflated_MSMAll.32k_fs_LR.surf.gii'\n",
    "        \n",
    "        self.Rsrf=f'../data20/{subj}/Structural/{subj}.R.midthickness.32k_fs_LR.surf.gii'\n",
    "        self.Rcoords=nib.load(self.Rsrf).darrays[0].data\n",
    "        self.Laparc=f'../data20/{subj}/Structural/{subj}.L.aparc.a2009s.32k_fs_LR.label.gii'\n",
    "        self.Rinflated='/Users/austin/Documents/ParisHorizontal/32k_fs_LR/S1200.R.inflated_MSMAll.32k_fs_LR.surf.gii'\n",
    "\n",
    "        \n",
    "        self.Raparc=f'../data20/{subj}/Structural/{subj}.R.aparc.a2009s.32k_fs_LR.label.gii'\n",
    "        \n",
    "    \n",
    "        self.LZverts=get_zoneVerts(LWS)\n",
    "        self.RZverts=get_zoneVerts(RWS)\n",
    "    \n",
    "    \n",
    "        if self.pca is None:\n",
    "            ########## session 1 \n",
    "#             print('ussing diffusion maps')\n",
    "            self.gradses1=np.load(f'{subj}/{subj}.mapalign.ses1.diffmap.s0{kernel}mm.npy')\n",
    "        \n",
    "\n",
    "        \n",
    "            self.Lgradses1=self.gradses1[0][0:len(self.Lfill)]\n",
    "            self.Lgradses1=recort(self.Lgradses1,self.Lfill,self.dims)\n",
    "            self.Lgradses1=gradientOrientation(self.Lgradses1,'left',self.Laparc)\n",
    "    \n",
    "        \n",
    "            self.Rgradses1=self.gradses1[0][len(self.Lfill):]\n",
    "            self.Rgradses1=recort(self.Rgradses1,self.Rfill,self.dims)\n",
    "            self.Rgradses1=gradientOrientation(self.Rgradses1,'right',self.Raparc)\n",
    "        \n",
    "            ######## session 2 \n",
    " \n",
    "        \n",
    "            self.gradses2=np.load(f'{subj}/{subj}.mapalign.ses2.s0{kernel}mm.diffmap.npy')\n",
    "        \n",
    "            self.Lgradses2=self.gradses2[0][0:len(self.Lfill)]\n",
    "            self.Lgradses2=recort(self.Lgradses2,self.Lfill,self.dims)\n",
    "            self.Lgradses2=gradientOrientation(self.Lgradses2,'left',self.Laparc)\n",
    "    \n",
    "        \n",
    "            self.Rgradses2=self.gradses2[0][len(self.Lfill):]\n",
    "            self.Rgradses2=recort(self.Rgradses2,self.Rfill,self.dims)\n",
    "            self.Rgradses2=gradientOrientation(self.Rgradses2,'right',self.Raparc)\n",
    "            \n",
    "        else:\n",
    "#             print('using PCA maps')\n",
    "            ######### load PCA grads\n",
    "            self.gradses1=np.load(f'{subj}/{subj}.pca.ses1.s0{kernel}mm.npy')\n",
    "            self.Lgradses1=self.gradses1[0][0:len(self.Lfill)]\n",
    "            self.Lgradses1=recort(self.Lgradses1,self.Lfill,self.dims)\n",
    "            self.Lgradses1=gradientOrientation(self.Lgradses1,'left',self.Laparc)\n",
    "    \n",
    "        \n",
    "            self.Rgradses1=self.gradses1[0][len(self.Lfill):]\n",
    "            self.Rgradses1=recort(self.Rgradses1,self.Rfill,self.dims)\n",
    "            self.Rgradses1=gradientOrientation(self.Rgradses1,'right',self.Raparc)\n",
    "        \n",
    "            self.gradses2=np.load(f'{subj}/{subj}.pca.ses2.s0{kernel}mm.npy')   \n",
    "            self.Lgradses2=self.gradses2[0][0:len(self.Lfill)]\n",
    "            self.Lgradses2=recort(self.Lgradses2,self.Lfill,self.dims)\n",
    "            self.Lgradses2=gradientOrientation(self.Lgradses2,'left',self.Laparc)\n",
    "    \n",
    "        \n",
    "            self.Rgradses2=self.gradses2[0][len(self.Lfill):]\n",
    "            self.Rgradses2=recort(self.Rgradses2,self.Rfill,self.dims)\n",
    "            self.Rgradses2=gradientOrientation(self.Rgradses2,'right',self.Raparc)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def print_subj(self):\n",
    "        print(self.subj)\n",
    "    \n",
    "    \n",
    "    ### extract the vertices associated with each zone\n",
    "    def zoning(self,Lgrad,Rgrad):\n",
    "        Lg_zone=[]\n",
    "        for key in self.LZverts:\n",
    "            Lroi=self.LZverts[key]\n",
    "            Lg_zone.append(Lgrad[0][Lroi])\n",
    "        \n",
    "        Rg_zone=[]\n",
    "\n",
    "        for key in self.RZverts:\n",
    "            Rroi=self.RZverts[key]\n",
    "            Rg_zone.append(Rgrad[0][Rroi])\n",
    "        return Lg_zone,Rg_zone\n",
    "\n",
    "    \n",
    "    def extract_topX(self,Left,Right,pct):\n",
    "        \"\"\"extract the top X percent instead of binning\"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        #######################################################\n",
    "        #######################################################\n",
    "        #######################################################\n",
    "        # ADD CHECK HERE TO MAKE SURE IT IS A VALID GRADIENT WITH THE L[1] AND R[1]\n",
    "        # THESE ARE SAVED AND HERE TO BE USED. DON'T WASTE THAT CHECK\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        Left=Left[0]\n",
    "        Right=Right[0]\n",
    "        Lout=np.zeros(self.dims)\n",
    "        Rout=np.zeros(self.dims)\n",
    "        \n",
    "        Lpct=np.percentile(Left[self.Lfill],pct)\n",
    "        \n",
    "        \n",
    "        Lthr=np.where(Left[self.Lfill]>Lpct)[0]\n",
    "        Linter=np.zeros(len(self.Lfill))\n",
    "        Linter[Lthr]=1\n",
    "        L=recort(Linter,self.Lfill,self.dims)\n",
    "        L=np.where(L!=0)[0]\n",
    "        \n",
    "        #### do right \n",
    "        \n",
    "                \n",
    "        Rpct=np.percentile(Right[self.Rfill],pct)\n",
    "        \n",
    "        \n",
    "        Rthr=np.where(Right[self.Rfill]>Rpct)[0]\n",
    "        Rinter=np.zeros(len(self.Rfill))\n",
    "        Rinter[Rthr]=1\n",
    "        R=recort(Rinter,self.Rfill,self.dims)\n",
    "        R=np.where(R!=0)[0]\n",
    "        \n",
    "\n",
    "        return L,R\n",
    "    \n",
    "    def ZoneDice_Ses12(self,pct):\n",
    "        S1=self.extract_topX(self.Lgradses1,self.Rgradses1,pct)\n",
    "        S2=self.extract_topX(self.Lgradses2,self.Rgradses2,pct)\n",
    "        Ldx=[]\n",
    "        for l in self.LZverts:\n",
    "            roi=self.LZverts[l]\n",
    "            S1ZnL=np.intersect1d(roi,S1[0])\n",
    "            S2ZnL=np.intersect1d(roi,S2[0])\n",
    "            diceLZn=dice_it(S1ZnL,S2ZnL)\n",
    "            Ldx.append(diceLZn)\n",
    "        Rdx=[]\n",
    "        for r in self.RZverts:\n",
    "            roi=self.RZverts[r]\n",
    "            S1ZnR=np.intersect1d(roi,S1[1])\n",
    "            S2ZnR=np.intersect1d(roi,S2[1])\n",
    "            diceRZn=dice_it(S1ZnR,S2ZnR)\n",
    "            Rdx.append(diceRZn)\n",
    "        \n",
    "        posteriorZones=[1,4,6]\n",
    "        Ldx=[Ldx[i] for i in posteriorZones]\n",
    "        Rdx=[Rdx[i] for i in posteriorZones]\n",
    "        \n",
    "        return np.asarray(Ldx),np.asarray(Rdx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def dice_Ses12(self,pct):\n",
    "        S1=self.extract_topX(self.Lgradses1,self.Rgradses1,pct)\n",
    "        S2=self.extract_topX(self.Lgradses2,self.Rgradses2,pct)\n",
    "      \n",
    "        diceL=dice_it(S1[0],S2[0])\n",
    "        diceR=dice_it(S1[1],S2[1])\n",
    "        \n",
    "        \n",
    "        return np.asarray([diceL,diceR])\n",
    "    \n",
    "    \n",
    "    ############ implement the jaccard metric too\n",
    "    def ZoneJaccard_Ses12(self,pct):\n",
    "        S1=self.extract_topX(self.Lgradses1,self.Rgradses1,pct)\n",
    "        S2=self.extract_topX(self.Lgradses2,self.Rgradses2,pct)\n",
    "        Ldx=[]\n",
    "        for l in self.LZverts:\n",
    "            roi=self.LZverts[l]\n",
    "            S1ZnL=np.intersect1d(roi,S1[0])\n",
    "            S2ZnL=np.intersect1d(roi,S2[0])\n",
    "            diceLZn=jaccard_it(S1ZnL,S2ZnL)\n",
    "            Ldx.append(diceLZn)\n",
    "        Rdx=[]\n",
    "        for r in self.RZverts:\n",
    "            roi=self.RZverts[r]\n",
    "            S1ZnR=np.intersect1d(roi,S1[1])\n",
    "            S2ZnR=np.intersect1d(roi,S2[1])\n",
    "            diceRZn=jaccard_it(S1ZnR,S2ZnR)\n",
    "            Rdx.append(diceRZn)\n",
    "        \n",
    "        posteriorZones=[1,4,6]\n",
    "        Ldx=[Ldx[i] for i in posteriorZones]\n",
    "        Rdx=[Rdx[i] for i in posteriorZones]\n",
    "        \n",
    "        return np.asarray(Ldx),np.asarray(Rdx)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def Jaccard_Ses12(self,pct):\n",
    "        S1=self.extract_topX(self.Lgradses1,self.Rgradses1,pct)\n",
    "        S2=self.extract_topX(self.Lgradses2,self.Rgradses2,pct)\n",
    "      \n",
    "        diceL=jaccard_it(S1[0],S2[0])\n",
    "        diceR=jaccard_it(S1[1],S2[1])\n",
    "        \n",
    "        \n",
    "        return np.asarray([diceL,diceR])\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "        \n",
    "    def plot_gradses1(self):\n",
    "        a,b=oh_mayavi(self.Lsrf,self.Lgradses1[0],'CMRmap')\n",
    "        mlab.clf()\n",
    "        c,d=oh_mayavi(self.Rsrf,self.Rgradses1[0],'CMRmap')\n",
    "        plot_srfs(a,b,d,c)\n",
    "        \n",
    "    def plot_gradses2(self):\n",
    "        a,b=oh_mayavi(self.Lsrf,self.Lgradses2[0],'CMRmap')\n",
    "        mlab.clf()\n",
    "        c,d=oh_mayavi(self.Rsrf,self.Rgradses2[0],'CMRmap')\n",
    "        plot_srfs(a,b,d,c)\n",
    "        \n",
    "    def plot_topX(self,Left,Right,pct):\n",
    "        L=np.zeros(self.dims)\n",
    "        R=np.zeros(self.dims)\n",
    "        \n",
    "        topX=self.extract_topX(Left,Right,pct)\n",
    "        L[topX[0]]=1\n",
    "        R[topX[1]]=1\n",
    "        \n",
    "        a,b=oh_mayavi(self.Lsrf,L,'terrain',False)\n",
    "        mlab.clf()\n",
    "        c,d=oh_mayavi(self.Rsrf,R,'terrain',False)\n",
    "        plot_srfs(a,b,d,c)\n",
    "        \n",
    "        \n",
    "    def plot_ThrIntersectCortex(self,pct):\n",
    "        \n",
    "        L=np.zeros(self.dims)\n",
    "        R=np.zeros(self.dims)\n",
    "        \n",
    "        topXSes1=self.extract_topX(self.Lgradses1,self.Rgradses1,pct)\n",
    "        topXSes2=self.extract_topX(self.Lgradses2,self.Rgradses2,pct)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        L1=topXSes1[0]\n",
    "        L2=topXSes2[0]\n",
    "        Linter=np.intersect1d(L1,L2)\n",
    "        Lunion=np.union1d(L1,L2)\n",
    "        \n",
    "#         print(f'Left Dice is {dice_it(L1,L2)}')\n",
    "#         print(f'Left Jaccard is {jaccard_it(L1,L2)}')\n",
    "        \n",
    "        L[Lunion]=5\n",
    "        L[Linter]=10\n",
    "        \n",
    "        R1=topXSes1[1]\n",
    "        R2=topXSes2[1]\n",
    "        Rinter=np.intersect1d(R1,R2)\n",
    "        Runion=np.union1d(R1,R2)\n",
    "        \n",
    "#         print(f'Right Dice is {dice_it(R1,R2)}')\n",
    "#         print(f'Right Jaccard is {jaccard_it(R1,R2)}')\n",
    "        \n",
    "        R[Runion]=5\n",
    "        R[Rinter]=10\n",
    "        \n",
    "        a,b=oh_mayavi(self.Linflated,L,'PuBuGn',False)\n",
    "        mlab.clf()\n",
    "        d,c=oh_mayavi(self.Rinflated,R,'PuBuGn',False)\n",
    "        \n",
    "#         a,b=oh_mayavi(self.Lsrf,L,'PuBuGn',False)\n",
    "#         c,d=oh_mayavi(self.Rsrf,R,'PuBuGn',False)\n",
    "        plot_srfs_dice(a,b,c,d,f'{self.subj} Threshold {pct}',f'Left Dice is {dice_it(L1,L2):.2f}',f'Right Dice is {dice_it(R1,R2):.2f}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb6179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook initialized with png backend.\n"
     ]
    }
   ],
   "source": [
    "#### initialize the plotting backend for mayavi \n",
    "mlab.init_notebook('png',150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6eed64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aacf78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "347d57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get zone colormaps\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "zoneColors=[(131,229,250),(131,229,250),(13,60,124),(13,60,124),\n",
    "            (77,135,45),(77,135,45),\n",
    "            (74,140,197),(74,140,197),\n",
    "            (65,250,95),(65,250,95),\n",
    "            (227,150,52),(227,150,52),\n",
    "            (170,239,112),(170,239,112),\n",
    "            (250,97,191),(250,97,191),\n",
    "            (119,68,196),(119,68,196)]\n",
    "colors = [(e[0] / 255.0, e[1] / 255.0, e[2] / 255.0) for e in zoneColors]\n",
    "cmap = ListedColormap(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr=[50,55,60,65,70,75,80,85,90,95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=prep_plotting('100206',6,pca=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ac0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = sn.color_palette(palette='Set2',n_colors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aee378",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions={}\n",
    "regions['Left Hemisphere']=0\n",
    "regions['Right Hemisphere']=1\n",
    "regions['Left Lateral Parietal']=2\n",
    "regions['Left Temporal']=3\n",
    "regions['Left Medial Parietal']=4\n",
    "regions['Right Lateral Parietal']=5\n",
    "regions['Right Temporal']=6\n",
    "regions['Right Medial Parietal']=7\n",
    "\n",
    "kernels=[2, 4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee442a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot dice scores corrected for number of subjects from group \n",
    "for key in regions:\n",
    "    f, ax = plt.subplots(ncols=5,nrows=1,figsize=(16,6))\n",
    "    plt.subplot(151)\n",
    "    plot_itHue(2,regions[key])\n",
    "    plt.subplot(152)\n",
    "    plot_itHue(4,regions[key])\n",
    "    plt.subplot(153)\n",
    "    plot_itHue(6,regions[key])\n",
    "    plt.gca().set_title(key,fontsize = 20)\n",
    "    plt.subplot(154)\n",
    "    plot_itHue(8,regions[key])\n",
    "    plt.subplot(155)\n",
    "    plot_itHue(10,regions[key],legend=True)\n",
    "    \n",
    "    plt.savefig(f'../Dice_overlap/{key}_corr.png',facecolor='w')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot dice scores uncorrected for number of subjects left in group \n",
    "for key in regions:\n",
    "    f, ax = plt.subplots(ncols=5,nrows=1,figsize=(16,6))\n",
    "    plt.subplot(151)\n",
    "    plot_itHue(2,regions[key],corr=False)\n",
    "    plt.subplot(152)\n",
    "    plot_itHue(4,regions[key],corr=False)\n",
    "    plt.subplot(153)\n",
    "    plot_itHue(6,regions[key],corr=False)\n",
    "    plt.gca().set_title(key,fontsize = 20)\n",
    "    plt.subplot(154)\n",
    "    plot_itHue(8,regions[key],corr=False)\n",
    "    plt.subplot(155)\n",
    "    plot_itHue(10,regions[key],corr=False,legend=True)\n",
    "    \n",
    "    plt.savefig(f'../Dice_overlap/{key}_uncorr.png',facecolor='w')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e66e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### get rejects\n",
    "pc_reject=[]\n",
    "dm_reject=[]\n",
    "\n",
    "dm_dirtySubj=[]\n",
    "pc_dirtySubj=[]\n",
    "kernels=[2,4,6,8,10]\n",
    "for k in kernels:\n",
    "    \n",
    "    a=prep_plotsXkernel(k)\n",
    "    dm_reject.append(len(subjects)-len(a[8]))\n",
    "    dm_dirtySubj.append(a[8])\n",
    "    \n",
    "    b=prep_plotsXkernel(k,pca=True)\n",
    "    pc_reject.append(len(subjects)-len(b[8]))\n",
    "    pc_dirtySubj.append(b[8])\n",
    "    \n",
    "dm_reject=np.asarray(dm_reject)\n",
    "pc_reject=np.asarray(pc_reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623813a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sn.set()\n",
    "g=sn.lineplot(x=kernels,y=dm_reject,markers=True, dashes=True,marker='o',label='Dmap')\n",
    "g=sn.lineplot(x=kernels,y=pc_reject,markers=True, dashes=True,marker='o',label='PCA')\n",
    "g.set_xticks(kernels)\n",
    "g.set_xlabel('Smoothing kernel')\n",
    "g.set_ylabel('Subjects included in Dice')\n",
    "g.set_title('Canonical first gradient')\n",
    "plt.savefig('subjects_perkernel.png',facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm6_dirt=dm_dirtySubj[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_dirtySubj=set(flatten(dm_dirtySubj))\n",
    "pc_dirtySubj=set(flatten(pc_dirtySubj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf51444",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_6mm=list(set(subjects).difference(mm6_dirt))\n",
    "clean_dm=list(set(subjects).difference(dm_dirtySubj))\n",
    "clean_pc=list(set(subjects).difference(pc_dirtySubj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlab.options.offscreen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb824bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p indi6m_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7f76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl_subj in clean_6mm[0:8]:\n",
    "    thr=90\n",
    "    data=hcp_subj(cl_subj,6)\n",
    "    data.plot_ThrIntersectCortex(thr)\n",
    "    plt.savefig(f'indi6m_90/{data.subj}.dmap.thr0{thr}.s06mm.png',facecolor='w',pad_inches = 0.1,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8edd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr=[50, 55, 60, 65, 70, 75, 80, 85, 90, 95]\n",
    "kernels=[2,4,6,8,10]\n",
    "!mkdir -p ../subject_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90d83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subjectThresholdsAndSmoothing_dmap(subj):\n",
    "    cl_subj=subj\n",
    "    kernels=[2,4,6,8,10]\n",
    "    thr=[50,55,60,65,70,75,80,85,90,95]\n",
    "    for k in kernels:\n",
    "        !mkdir -p ./tmp\n",
    "        data=hcp_subj(cl_subj,k)\n",
    "        for i in thr:\n",
    "            data.plot_ThrIntersectCortex(i)\n",
    "            plt.savefig(f'tmp/{data.subj}.dmap.thr0{i}.s0{k}mm.png',facecolor='w',pad_inches = 0.1,bbox_inches='tight')\n",
    "            plt.close()\n",
    "            plt.cla()\n",
    "            plt.clf()\n",
    "            mlab.clf()\n",
    "            mlab.close()\n",
    "        !convert tmp/*png +append ../subject_dice/{data.subj}.dmap.s0{k}mm.png\n",
    "        !rm tmp/*png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21cc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subjectThresholdsAndSmoothing_pca(subj):\n",
    "    cl_subj=subj\n",
    "    kernels=[2,4,6,8,10]\n",
    "    thr=[50,55,60,65,70,75,80,85,90,95]\n",
    "    for k in kernels:\n",
    "        !mkdir -p ./tmp\n",
    "        data=hcp_subj(cl_subj,k,pca=True)\n",
    "        for i in thr:\n",
    "            data.plot_ThrIntersectCortex(i)\n",
    "            plt.savefig(f'tmp/{data.subj}.pca.thr0{i}.s0{k}mm.png',facecolor='w',pad_inches = 0.1,bbox_inches='tight')\n",
    "            plt.close()\n",
    "            plt.cla()\n",
    "            plt.clf()\n",
    "            mlab.clf()\n",
    "            mlab.close()\n",
    "        !convert tmp/*png +append ../subject_dice/{data.subj}.pca.s0{k}mm.png\n",
    "        !rm tmp/*png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bdbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subjectThresholdsAndSmoothing_dmap('101309')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b56dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n",
      "Context leak detected, msgtracer returned -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_subjectThresholdsAndSmoothing_pca('101309')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c263327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
